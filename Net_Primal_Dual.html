<!DOCTYPE html>
<html lang="en">

<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="author" content="Louise Naud">
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- For code display: Code Prettify -->
    <script src="https://cdn.rawgit.com/google/code-prettify/master/loader/run_prettify.js?skin=desert"></script>


    <title>Fun with the ROF model</title>

    <!-- Bootstrap Core CSS -->
    <link href="vendor/bootstrap/css/bootstrap.css" rel="stylesheet">

    <!-- Theme CSS -->
    <link href="css/clean-blog.css" rel="stylesheet">

    <!-- Custom Fonts -->
    <link href="vendor/font-awesome/css/font-awesome.min.css" rel="stylesheet" type="text/css">
    <link href='https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel='stylesheet' type='text/css'>

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
    <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

    <script type="text/javascript" async
            src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML">
    </script>
    <script type="text/x-mathjax-config">
MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
</script>
    <!-- Configuration for Mathjax and AlgoType-->
    <script type="text/x-mathjax-config">
MathJax.Hub.Config({
    extensions: ["tex2jax.js", "color.js"],
    jax: ["input/TeX", "output/HTML-CSS"],
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
        processEscapes: true
    },
    "HTML-CSS": { availableFonts: ["TeX"] },
    TeX: {
        Macros: {
                    And:     "\\\\mathbf{and}",
                    Or:      "\\\\mathbf{or}",
                    Not:     "\\\\mathbf{not}",
                    Is:      "\\\\mathbf{is}",
                    In:      "\\\\mathbf{in}",
                    Mapped:  "\\\\mathbf{mapped}",
                    Nil:     "\\\\mathbf{nil}"
        }
    }
});
</script>
    <!-- KateX for math formulas in pseudo code -->
    <link rel="stylesheet" href="katex/katex.min.css">
    <script src="katex/katex.min.js"></script>
    <!-- Stylesheet for pseudo code -->
    <link rel="stylesheet" href="pseudocode/pseudocode.min.css">
    <script src="pseudocode/pseudocode.min.js"></script>
    <!-- Library for Pseudo Code -->
    <link rel="stylesheet" href="Algotype.js/algotype_my_config.css">
    <script type="text/javascript" async
            src="Algotype.js/algotype.js">
    </script>
</head>




<body>

<!-- Navigation -->
<nav class="navbar navbar-default navbar-custom navbar-fixed-top">
    <div class="container-fluid">
        <!-- Brand and toggle get grouped for better mobile display -->
        <div class="navbar-header page-scroll">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                <span class="sr-only">Toggle navigation</span>
                Menu <i class="fa fa-bars"></i>
            </button>
            <a class="navbar-brand" href="index.html">ML Food for the Soul</a>
        </div>

        <!-- Collect the nav links, forms, and other content for toggling -->
        <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
            <ul class="nav navbar-nav navbar-right">
                <li>
                    <a href="index.html">Home</a>
                </li>
                <li>
                    <a href="about.html">About</a>
                </li>
                <li>
                    <a href="blog-tickets-list.html">Posts</a>
                </li>
                <li>
                    <a href="contact.html">Contact</a>
                </li>
            </ul>
        </div>
        <!-- /.navbar-collapse -->
    </div>
    <!-- /.container -->
</nav>

<!-- Page Header -->
<!-- Set your background image for this header on the line below. -->
<header class="intro-header" style="background-image: url('img/saddle.png')">
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <div class="post-heading">
                    <h1>Let's have fun with the ROF model</h1>
                    <h2 class="subheading">How to learn a more generic model.</h2>
                    <span class="meta">Posted by <a href="contact.html">Louise</a> on October 12, 2017</span>
                </div>
            </div>
        </div>
    </div>
</header>

<!-- Post Content -->
<article>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <p>In my previous post, I described a powerful optimization framework known as the Primal Dual
                    Framework. The goal of this new post is to have a little bit of fun with the ROF model and the
                    primal dual framework!
                </p>
                <p>While the ROF model is efficient for denoising, its form is hand crafted, and one might wonder if
                there might be a more optimal formulation for this problem. Since the Primal Dual Framework
                    works for a more general set of problems, i.e.:</p>

                <p>
                    $$
                    \begin{align}
                    & \underset{x}{\text{minimize}} & &  M(x) + R(Lx)
                    \end{align}
                    $$
                    with:
                <ul>
                    <li>\(M\) a lower semi continuous function </li>
                    <li>\(R\) a lower semi continuous function</li>
                    <li>\(L\) a continuous linear operator</li>
                </ul>
                <p>we are going to explore in this post the possibility of learning these functions \(M\), \(R\)and
                    \(L\) through a neural net with the observed images as input and the ground truth images as
                    outputs. The layers will be custom layers consisting of the parametrized Primal Dual steps. The
                    goal will be to optimize these parameters.
                </p>
                <p>The idea here is a bit similar to the <a href="https://arxiv.org/pdf/1703.00443.pdf">OptNet</a> paper. </p>


                <h2 class="section-heading">A more general formulation of the ROF model</h2>
                <p>But first, let's begin by giving a more general formulation of the ROF model:
                    $$
                    \begin{align}
                    & \underset{x}{\text{minimize}} & &  \frac{1}{2} x^T H x + b^T x + \left\| Lx \right\|_1
                    \end{align}
                    $$
                    with:
                <ul>
                    <li>\(H\) a symmetric invertible matrix of \(\mathcal{M}_n(\mathbb{R}^n\))</li>
                    <li>\(b\) is a vector in \(\mathbb{R}^n\)</li>
                    <li>\(L\) is a continuous linear operator</li>
                </ul>
                We are going to note this function to minimize \(P(x; H, b, L)\).
                </p>
                <p>Let's now use the following caracterization of a norm : \(\left\| Lx \right\|_1 =
                    \underset{y \in [-1, 1]^n}{\max}\langle L^T y, x \rangle\) in order to introduce a saddle problem
                    formulation. The problem can now be written:
                    $$
                    \begin{align}
                    & \underset{x}{\min} \underset{y \in [-1, 1]^n }{\max}& &  \frac{1}{2} x^T H x + \langle b + L^T
                    y, x
                    \rangle
                    \end{align}
                    $$
                    A simple gradient computation gives: \(x^* = -H^{-1} (b + L^T y) \). The dual problem is then:

                    $$
                    \begin{align}
                    & \underset{y \in [-1, 1]^n}{\text{maximize}} & &  -\frac{1}{2} (b+L^T y )^T H^{-1} (b+L^Ty)
                    \end{align}
                    $$
                    We are going to note this function to maximize \(D(y; H, b, L)\).
                </p>
                <p>The primal-dual gap is defined as : \(G(x, y ; H, b, L) = P(x; H, b, L) - D(y; H, b, L)\). Since this is
                    a saddle point problem, we have that \(G(x^*, y^* ; H, b, L) = G(x^* ; H, b, L) = 0 \)</p>

                <p>Now, we are going to consider this optimization problem through a computational graph view. It looks very similar
                to the one in the excellent paper <a href="https://arxiv.org/pdf/1606.04474.pdf">Learning to learn by gradient descent by gradient descent</a></p>:
                <a href="#">
                    <img class="img-responsive" src="img/computational_graph_pd.png" alt="">
                </a>
                <p>If we note \(\theta_t = (H, b, L)_t\) the vector of parameters that we are trying to learn in the Primal Dual problem, \(\mathcal{PD}\) the recurrent neural net that unrolls \(n\) iterations of the Primal Dual algorithm, \(\tilde{x}_t\) the primal variable after \(nk\) iterations, \(k \in \mathbb{N}\).</p>


                <h2 class="section-heading">Let's start by learning a simple linear operator</h2>
                <p>In the previous general model, if we pose \( H = I_n \), \( b = -2 img_{obs}\) and
                    \(L : x \mapsto \sum_{(i, j) \in \mathcal{E}} \|x_i -x_j \|_1\), we can get back to the usual ROF model, as formulated in the Chambolle Pock paper:
                    $$
                    \begin{align}
                    & \underset{x}{\text{minimize}} & &   \| x - img_{obs} \|_2^2  + \frac{\lambda}{2} \left\| Lx \right\|_1
                    \end{align}
                    $$


                    Since this model has been studied in the previous blog post, we are going to introduce the linear operator \(L : x ; w \mapsto \sum_{(i, j) \in \mathcal{E}} w_{i,j} \|x_i -x_j \|_1\), i.e \(L = W \odot \nabla\), \(\odot \) being the Hadamard product here.
                    A calculation shows that \(L\) is a linear operator, and that its adjoint \(L^T\) is \( L^T : y \mapsto  - div(W \odot y) \).

                    Here are the noised, denoised and original images.
                    In this first new scenario, we are going to minimize the Mean Squared Error between the Ground Truth and the primal variable after \( n\) iterations of the primal dual algorithm:

                    $$
                    \begin{align}
                    & \underset{w}{\text{minimize}} & &  \sum{\left\| x_i^{*} - x_i^{GT} \right\|_2^2 } \\
                    & ST & & x_i^{*} = \underset{x}{\arg \min P(x; w)}
                    \end{align}
                    $$

                     Each function was optimized for 80 steps and the trained optimizers were unrolled for 15 steps, with the following set of parameters: \(\sigma_n = 0.1, max_{it} = 15, max_{epochs}=80, \lambda_{ROF}=7.0, \theta = 0.75, \tau = 0.01 \)
                </p>
                    <a href="#">
                        <img class="img-responsive" src="img/lena_noised.png" alt="">
                    </a>

                    <a href="#">
                        <img class="img-responsive" src="img/lena_denoised.png" alt="">
                    </a>

                    <a href="#">
                        <img class="img-responsive" src="img/image_Lena512.png" alt="">
                    </a>

                <p>If we now use the trained network on a test image, which has the same amount of noise than in the training image: </p>

                    <a href="#">
                        <img class="img-responsive" src="img/barbara_noised.png" alt="">
                    </a>

                    <a href="#">
                        <img class="img-responsive" src="img/barbara_denoised.png" alt="">
                    </a>

                    <a href="#">
                        <img class="img-responsive" src="img/image_Barbara512.png" alt="">
                    </a>

                <p>It seems to denoise pretty nicely!</p>

                <h2 class="section-heading">Python Code Example with PyTorch</h2>
                <p> Here is how I organized the code with PyTorch, with GPU support. Every function needed in the Primal Dual Net is coded as a nn.Module submodule:</p>

                <pre class="prettyprint">
    <code class="language-python">
from torch.autograd import Variable
import torch
import torch.nn as nn

class ForwardWeightedGradient(nn.Module):
    def __init__(self):
        super(ForwardWeightedGradient, self).__init__()

    def forward(self, x, w, dtype=torch.cuda.FloatTensor):
        """

        :param x: PyTorch Variable [1xMxN]
        :param w: PyTorch Variable [2xMxN]
        :param dtype: Tensor type
        :return: PyTorch Variable [2xMxN]
        """
        im_size = x.size()
        gradient = Variable(torch.zeros((2, im_size[1], im_size[2])).type(dtype))  # Allocate gradient array
        # Horizontal direction
        gradient[0, :, :-1] = x[0, :, 1:] - x[0, :, :-1]
        # Vertical direction
        gradient[1, :-1, :] = x[0, 1:, :] - x[0, :-1, :]
        gradient = gradient * w
        return gradient


class BackwardWeightedDivergence(nn.Module):
    def __init__(self):
        super(BackwardWeightedDivergence, self).__init__()

    def forward(self, y, w, dtype=torch.cuda.FloatTensor):
        """

        :param y: PyTorch Variable, [2xMxN], dual variable
        :param dtype: tensor type
        :return: PyTorch Variable, [1xMxN], divergence
        """
        im_size = y.size()
        y_w = w.cuda() * y
        # Horizontal direction
        d_h = Variable(torch.zeros((1, im_size[1], im_size[2])).type(dtype))
        d_h[0, :, 0] = y_w[0, :, 0]
        d_h[0, :, 1:-1] = y_w[0, :, 1:-1] - y_w[0, :, :-2]
        d_h[0, :, -1] = -y_w[0, :, -2:-1]

        # Vertical direction
        d_v = Variable(torch.zeros((1, im_size[1], im_size[2])).type(dtype))
        d_v[0, 0, :] = y_w[1, 0, :]
        d_v[0, 1:-1, :] = y_w[1, 1:-1, :] - y_w[1, :-2, :]
        d_v[0, -1, :] = -y_w[1, -2:-1, :]

        # Divergence
        div = d_h + d_v
        return div


class PrimalWeightedUpdate(nn.Module):
    def __init__(self, lambda_rof, tau):
        super(PrimalWeightedUpdate, self).__init__()
        self.backward_div = BackwardWeightedDivergence()
        self.tau = tau
        self.lambda_rof = lambda_rof

    def forward(self, x, y, img_obs, w):
        """

        :param x: PyTorch Variable [1xMxN]
        :param y: PyTorch Variable [2xMxN]
        :param img_obs: PyTorch Variable [1xMxN]
        :return:Pytorch Variable, [1xMxN]
        """
        x = (x + self.tau * self.backward_div.forward(y, w) +
             self.lambda_rof * self.tau * img_obs) / (1.0 + self.lambda_rof * self.tau)
        return x

class DualWeightedUpdate(nn.Module):
    def __init__(self, sigma):
        super(DualWeightedUpdate, self).__init__()
        self.forward_grad = ForwardWeightedGradient()
        self.sigma = sigma

    def forward(self, x_tilde, y, w):
        """

        :param x_tilde: PyTorch Variable, [1xMxN]
        :param y: PyTorch Variable, [2xMxN]
        :param w: PyTorch Variable, [2xMxN]
        :return: PyTorch Variable, [2xMxN]
        """
        y = y + self.sigma * self.forward_grad.forward(x_tilde, w)
        return y


class PrimalRegularization(nn.Module):
    def __init__(self, theta):
        super(PrimalRegularization, self).__init__()
        self.theta = theta

    def forward(self, x, x_tilde, x_old):
        """

        :param x: PyTorch Variable, [1xMxN]
        :param x_tilde: PyTorch Variable, [1xMxN]
        :param x_old: PyTorch Variable, [1xMxN]
        :return: PyTorch Variable, [1xMxN]
        """
        x_tilde = x + self.theta * (x - x_old)
        return x_tilde


class PrimalDualNetwork(nn.Module):
    def __init__(self, w, max_it=10, lambda_rof=4.0, sigma=1. / (7.0 * 0.01), tau=0.01, theta=0.5):
        """

        :param w: PyTorch Variable, [2xMxN]
        :param max_it: int
        :param lambda_rof: float
        :param sigma: float
        :param tau: float
        :param theta: float
        """
        super(PrimalDualNetwork, self).__init__()
        self.max_it = max_it
        self.dual_update = DualWeightedUpdate(sigma)
        self.prox_l_inf = ProximalLinfBall()
        self.primal_update = PrimalWeightedUpdate(lambda_rof, tau)
        self.primal_reg = PrimalRegularization(theta)

        self.energy_primal = PrimalEnergyROF()
        self.energy_dual = DualEnergyROF()
        self.pe = 0.0
        self.de = 0.0
        self.w = w
        self.clambda = lambda_rof

    def forward(self, img_obs):
        """
        Forward function for the PrimalDualNet.
        :param img_obs: PyTorch Variable, [1xMxN]
        :return: PyTorch Variable, [1xMxN]
        """
        x = img_obs.clone().cuda()
        x_tilde = img_obs.clone().cuda()
        img_size = img_obs.size()
        y = Variable(torch.ones((img_size[0] + 1, img_size[1], img_size[2]))).cuda()

        for it in range(self.max_it):
            # Dual update
            y = self.dual_update.forward(x_tilde, y, self.w.cuda())
            y = self.prox_l_inf.forward(y, 1.0)
            # Primal update
            x_old = x
            x = self.primal_update.forward(x, y, img_obs, self.w.cuda())
            # Smoothing
            x_tilde = self.primal_reg.forward(x, x_tilde, x_old)
            # Compute energies
            self.pe = self.energy_primal.forward(x, img_obs.cuda(), self.w, self.clambda)
            self.de = self.energy_dual.forward(y, img_obs, self.w)

        return x_tilde
    </code>
</pre>
                <p>And now here is what the main looks like:</p>
<pre class="prettyprint">

from __future__ import print_function

import numpy as np
from PIL import Image
import matplotlib.pyplot as plt

import torch
import torch.nn as nn
from torch.autograd import Variable
import torchvision.transforms as transforms

import png
import argparse

from primal_dual_model import PrimalDualNetwork, ForwardGradient, BackwardDivergence, ForwardWeightedGradient


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='Run Primal Dual Net.')
    parser.add_argument('--use_cuda', type=bool, default=True,
    help='Flag to use CUDA, if available')
    parser.add_argument('--max_it', type=int, default=10,
    help='Number of iterations in the Primal Dual algorithm')
    parser.add_argument('--max_epochs', type=int, default=150,
    help='Number of epochs in the Primal Dual Net')
    parser.add_argument('--lambda_rof', type=float, default=5.,
    help='Lambda parameter in the ROF model')
    parser.add_argument('--theta', type=int, default=0.9,
    help='Regularization parameter in the Primal Dual algorithm')
    parser.add_argument('--tau', type=int, default=80,
    help='Parameter in Primal')
    parser.add_argument('--save_flag', type=bool, default=True,
    help='Flag to save or not the result images')

    args = parser.parse_args()

    max_epochs = args.max_epochs
    max_it = args.max_it
    lambda_rof = args.lambda_rof
    theta = args.theta
    tau = args.tau
    sigma = 1. / (lambda_rof * tau)
    # cuda
    use_cuda = (torch.cuda.is_available() and args.use_cuda)
    dtype = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor

    # Transforms PIL <-> PyTorch tensors
    pil2tensor = transforms.ToTensor()
    tensor2pil = transforms.ToPILImage()

    # Create image to noise and denoise / train the network on
    sigma_n = 0.1  # Noise variance
    img_ = Image.open("images/image_Lena512.png")
    h, w = img_.size
    img_ref = Variable(pil2tensor(img_).type(dtype))
    noise = torch.ones(img_ref.size())
    noise = Variable(noise.normal_(0.0, sigma_n).type(dtype))
    img_obs = img_ref + noise
    img_n = img_obs.data.cpu().numpy().reshape((512, 512))

    # Parameters
    norm_l = 7.0
    max_it = 200
    theta = 0.8
    tau = 0.01
    sigma = 1.0 / (norm_l * tau)
    lambda_rof = 8.0  # 7.0

    x = Variable(img_obs.data.clone().type(dtype))
    x_tilde = Variable(img_obs.data.clone().type(dtype))
    img_size = img_ref.size()
    y = Variable(torch.zeros((img_size[0]+1, img_size[1], img_size[2])).type(dtype))
    y = ForwardGradient().forward(x)
    g_ref = y.clone()

    # Net approach
    w = nn.Parameter(torch.rand(y.size()).type(dtype))
    n_w = torch.norm(w, 1, dim=0)
    plt.figure()
    plt.imshow(n_w.data.cpu().numpy())
    plt.colorbar()

    net = PrimalDualNetwork(w, max_it=max_it, lambda_rof=lambda_rof, sigma=sigma, tau=tau, theta=theta)
    criterion = torch.nn.MSELoss(size_average=False)
    optimizer = torch.optim.Adam(net.parameters(), lr=1e-2)
    params = list(net.parameters())
    loss_history = []
    primal_history = []
    dual_history = []
    gap_history = []
    learning_rate = 1e-4
        for t in range(max_epochs):
        # Forward pass: Compute predicted image by passing x to the model
        x_pred = net(x)
        # Compute and print loss
        loss = criterion(x_pred, img_ref)
        print(t, loss.data[0])
        loss_history.append(loss.data[0])
        # Zero gradients, perform a backward pass, and update the weights.

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        # Compute energies and store them for plotting
        pe = net.pe.data[0]
        de = net.de.data[0]
        primal_history.append(pe)
        dual_history.append(de)
        gap_history.append(pe - de)

    f, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, sharex='col', sharey='row')

    ax1.imshow(np.array(img_))
    ax1.set_title("Reference image")
    ax2.imshow(np.array(tensor2pil(img_obs.data.cpu())).reshape(512, 512))
    ax2.set_title("Observed image")
    ax3.imshow(np.array(tensor2pil(x_pred.data.cpu())).reshape(512, 512))
    ax3.set_title("Denoised image")
    ax4.imshow(np.abs(np.array(tensor2pil(img_obs.data.cpu())) - np.array(tensor2pil(x_pred.data.cpu()))))

    # Save results if specified so:
    if args.save_flag:
        f = open('lena_noised.png', 'wb')
        w1 = png.Writer(512, 512, greyscale=True)
        w1.write(f, np.array(tensor2pil(img_obs.data.cpu())))
        f.close()
        f_res = open('lena_denoised.png', 'wb')
        w1.write(f_res, np.array(tensor2pil(x_pred.data.cpu())).reshape(512, 512))
        f_res.close()
    # Test image
    img_t = Image.open("images/image_Barbara512.png")
    h, w1 = img_t.size
    img_ref_t = Variable(pil2tensor(img_t).type(dtype))
    noise_2 = torch.ones(img_ref_t.size())
    noise_2 = Variable(noise_2.normal_(0.0, sigma_n).type(dtype))
    img_obs_t = img_ref_t + noise
    img_dn = net.forward(img_obs_t)

    f2, ((ax21, ax22), (ax23, ax24)) = plt.subplots(2, 2, sharex='col', sharey='row')
    ax21.imshow(np.array(img_t))
    ax21.set_title("Reference image")
    ax22.imshow(img_obs_t.data.cpu().mul_(255).numpy().reshape(512, 512))
    ax22.set_title("Observed image")
    ax23.imshow(img_dn.data.cpu().mul_(255).numpy().reshape(512, 512))
    ax23.set_title("Denoised image")

</code>
</pre>


                <p>The code (and images as well) is available in its full <a href="https://github.com/louisenaud/pytorch_primal_dual">here</a>. </p>

                <p>In the next part of this ticket, I will implement the general form of the aforementionned problem.</p>




                <p>You can leave comments down here, or contact me through the contact form of this blog if you
                    have questions or remarks on this post!</p>
                <!-- Blog Comments -->

                <!-- begin wwww.htmlcommentbox.com -->
                <div id="HCB_comment_box"><a href="http://www.htmlcommentbox.com">Widget</a> is loading comments...</div>
                <link rel="stylesheet" type="text/css" href="//www.htmlcommentbox.com/static/skins/bootstrap/twitter-bootstrap.css?v=0" />
                <script type="text/javascript" id="hcb"> /*<!--*/ if(!window.hcb_user){hcb_user={};} (function(){var s=document.createElement("script"), l=hcb_user.PAGE || (""+window.location).replace(/'/g,"%27"), h="//www.htmlcommentbox.com";s.setAttribute("type","text/javascript");s.setAttribute("src", h+"/jread?page="+encodeURIComponent(l).replace("+","%2B")+"&mod=%241%24wq1rdBcg%24rbyy1KYA6pUs1Jh9BfMHZ."+"&opts=16862&num=10&ts=1498161055918");if (typeof s!="undefined") document.getElementsByTagName("head")[0].appendChild(s);})(); /*-->*/ </script>
                <!-- end www.htmlcommentbox.com -->


            </div>
        </div>
    </div>
    </div>
    </div>
</article>

<hr>

<!-- Footer -->
<footer>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <ul class="list-inline text-center">
                    <li>
                        <a href="https://twitter.com/naud_louise">
                                <span class="fa-stack fa-lg">
                                    <i class="fa fa-circle fa-stack-2x"></i>
                                    <i class="fa fa-twitter fa-stack-1x fa-inverse"></i>
                                </span>
                        </a>
                    </li>
                    <li>
                        <a href="https://www.facebook.com/louise.naud1">
                                <span class="fa-stack fa-lg">
                                    <i class="fa fa-circle fa-stack-2x"></i>
                                    <i class="fa fa-facebook fa-stack-1x fa-inverse"></i>
                                </span>
                        </a>
                    </li>
                    <li>
                        <a href="https://github.com/louisenaud">
                                <span class="fa-stack fa-lg">
                                    <i class="fa fa-circle fa-stack-2x"></i>
                                    <i class="fa fa-github fa-stack-1x fa-inverse"></i>
                                </span>
                        </a>
                    </li>
                </ul>
                <p class="copyright text-muted">Copyright &copy; Louise Naud 2017</p>
            </div>
        </div>
    </div>
</footer>

<!-- jQuery -->
<script src="vendor/jquery/jquery.min.js"></script>

<!-- Bootstrap Core JavaScript -->
<script src="vendor/bootstrap/js/bootstrap.min.js"></script>

<!-- Contact Form JavaScript -->
<script src="js/jqBootstrapValidation.js"></script>
<script src="js/contact_me.js"></script>

<!-- Theme JavaScript -->
<script src="js/clean-blog.min.js"></script>

<script>
    var blocks = document.getElementsByClassName("pseudocode");
    for(var blockId = 0; blockId < blocks.length; blockId++) {
        var block = blocks[blockId];

        var code = block.textContent;
        var options = {
            lineNumber: true
        };

        var outputEl = document.createElement('div');
        outputEl.className += " pseudocode-out";
        block.parentNode.insertBefore(outputEl, block.nextSibling);

        pseudocode.render(code, outputEl, options);
    }

    while( blocks[0]) {
        blocks[0].parentNode.removeChild(blocks[0]);
    }
</script>
<!-- Google Analytics -->
<script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
            (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-52868500-2', 'auto');
    ga('send', 'pageview');

</script>

</body>

</html>
</title>
</head>
<body>

</body>
</html>